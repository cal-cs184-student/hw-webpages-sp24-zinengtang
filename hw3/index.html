<!DOCTYPE html>
<html>
<head>
	<meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
	<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <title>Graphics Homework 3</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        img { max-width: 100%; height: auto; }
        table { border-collapse: collapse; width: 100%; }
        td, th { border: 1px solid #dddddd; text-align: left; padding: 8px; }
        th { background-color: #f2f2f2; }
    </style>
</head>
<body>

<h1>Graphics Homework 3</h1> 
<p>Author: Zineng Tang</p>

<h1>Overview</h1>
<p>
This project focuses on implementing various techniques in computer graphics rendering, including ray generation, triangle intersection, BVH (Bounding Volume Hierarchy) construction, direct and indirect illumination, and adaptive sampling.
<br>
Ray Generation and Triangle Intersection: Implemented ray generation from the camera through each pixel, determining intersections with scene geometry using the Möller-Trumbore algorithm.
<br>
BVH Construction: Introduced a BVH acceleration structure to improve rendering efficiency.
<br>
Direct Illumination: Examined two sampling methods—uniform hemisphere sampling and importance sampling of lights—to calculate direct lighting.
<br>
Global Illumination: For indirect lighting, implemented recursive sampling based on the BSDF, employing Russian Roulette for termination.
<br>
Adaptive Sampling: Optimized rendering by varying sample rates per pixel based on variance in lighting conditions.

</p>
<h1>1. Rendering Pipeline: Ray Generation and Triangle Intersection</h1>

    <h2>Ray Generation</h2>
    <p>
        Ray generation involves creating rays that originate from the camera and pass through each pixel on the image plane. The process includes:
    </p>
    <ol>
        <li><strong>Camera Position and Orientation:</strong> Determine the position and orientation of the camera in the scene.</li>
        <li><strong>Viewing Frustum:</strong> Calculate the camera's viewing frustum, defined by the field of view (FOV), aspect ratio, and near and far clipping planes.</li>
        <li><strong>Pixel Sampling:</strong> For each pixel, calculate a direction vector from the camera position through the pixel, converting pixel coordinates to world coordinates.</li>
        <li><strong>Ray Construction:</strong> Construct a ray for each pixel with the direction vector and the camera's position. These rays intersect with the scene geometry to determine visible surfaces.</li>
    </ol>

    <h2>Triangle Intersection</h2>
    <p>
        The triangle intersection algorithm determines if and where a ray intersects a triangle in the scene, based on the Möller-Trumbore intersection algorithm:
    </p>
    <ol>
        <li><strong>Triangle Definition:</strong> Defined by its three vertices \(V_1, V_2, V_3\), calculate two edge vectors \(E_1 = V_2 - V_1\) and \(E_2 = V_3 - V_1\).</li>
        <li><strong>Determinant and Ray Direction:</strong> Calculate the determinant including the ray direction vector \(D\) and edge vectors \(E_1, E_2\) to find if the ray intersects the triangle's plane.</li>
        <li><strong>Barycentric Coordinates:</strong> Calculate the barycentric coordinates (\(u, v\)) to determine if the intersection point lies within the triangle.</li>
        <li><strong>Intersection Point:</strong> If \(0 \leq u \leq 1\), \(0 \leq v \leq 1\), and \(u + v \leq 1\), the ray intersects the triangle, determining the intersection point using \(t\).</li>
        <li><strong>Normal Calculation:</strong> Calculate the surface normal at the intersection point, which is constant for a flat triangle and calculated as the cross product of \(E_1\) and \(E_2\).</li>
    </ol>

<div style="text-align: center;">
    <figure>
        <img src="assets/1_0.png" style="width:20vw;">
	<img src="assets/1_1.png" style="width:20vw;">
	    <img src="assets/1_2.png" style="width:20vw;">
	<img src="assets/1_3.png" style="width:20vw;">
	    <img src="assets/1_4.png" style="width:20vw;">
	    <img src="assets/1_5.png" style="width:20vw;">
	    <img src="assets/1_6.png" style="width:20vw;">
	    <img src="assets/1_7.png" style="width:20vw;">
        <figcaption> Screenshots of normal shading.</figcaption>
    </figure>
</div>


	<h1>2. BVH Construction and Rendering with Normal Shading</h1>

    <h2>BVH Construction Algorithm</h2>
    <p>
        Bounding Volume Hierarchy (BVH) is a tree structure on a set of geometric objects. All geometric objects are wrapped in bounding volumes that form the leaf nodes of the tree. These nodes are then grouped as small sets and enclosed within larger bounding volumes. These, in turn, are also grouped and enclosed within other larger bounding volumes in a recursive manner until the whole scene is enclosed in a single bounding volume, forming the root of the BVH.
    </p>

    <h3>Why Picking the Splitting Point</h3>
    <p>
        The heuristic chosen for picking the splitting point in the BVH construction algorithm is the <strong>Surface Area Heuristic (SAH)</strong>. This heuristic minimizes the total cost of intersections by considering both the surface area of the bounding volumes and the number of primitives they contain. The SAH tries to find the split that minimizes the expression:
    </p>
    <p>\(Cost = C_{trav} + (P_{L} \cdot A_{L} + P_{R} \cdot A_{R}) / A_{total}\)</p>
    <ul>
        <li>\(C_{trav}\): Cost of traversing a node (fixed cost).</li>
        <li>\(P_{L}, P_{R}\): The number of primitives on the left and right side of the split.</li>
        <li>\(A_{L}, A_{R}, A_{total}\): The surface areas of the bounding volumes on the left, right, and the total surface area of the node being split.</li>
    </ul>
    <p>
        By evaluating this cost for possible splits at different positions and choosing the one with the lowest cost, the algorithm effectively balances the tree, reducing the overall number of intersection tests required during rendering.
    </p>

    <h2>Rendered Images with Normal Shading</h2>
    <p>Below are images rendered using BVH acceleration with normal shading, which significantly speeds up rendering times for complex scenes.</p>
    <div style="text-align: center;">
    <figure>
        <img src="assets/2_0.png" style="width:20vw;">
	<img src="assets/2_1.png" style="width:20vw;">
	<img src="assets/2_2.png" style="width:20vw;">
	    <img src="assets/2_3.png" style="width:20vw;">
	    <img src="assets/2_4.png" style="width:20vw;">
<img src="assets/2_5.png" style="width:20vw;">
        <figcaption> Examples of large dae files.</figcaption>
    </figure>
</div>

<h2>BVH Acceleration Impact Analysis</h2>
    <section>
        <p>The utilization of Bounding Volume Hierarchy (BVH) acceleration significantly improves rendering times across a variety of scenes with moderately complex geometries. When comparing the rendering times of scenes with and without BVH acceleration, it is evident that BVH acceleration drastically reduces the time required for rendering. This pattern is consistent across all tested scenes, showcasing the efficiency of BVH in handling complex geometries by effectively minimizing the number of intersection tests required. These results clearly illustrate the impact of BVH acceleration on rendering performance, making it an essential technique for reducing computational costs and improving the efficiency of rendering complex scenes.</p>
    </section>
    <section>
        <h3>Rendering Time Comparison</h3>
        <table>
            <tr>
                <th>File</th>
                <th>With BVH (s)</th>
                <th>Without BVH (s)</th>
            </tr>
            <tr>
                <td>CBdragon_microfacet_au.dae</td>
                <td>0.1178</td>
                <td>445</td>
            </tr>
            <tr>
                <td>CBdragon.dae</td>
                <td>0.1335</td>
                <td>521</td>
            </tr>
            <tr>
                <td>bunny_microfacet_cu_unlit.dae</td>
                <td>0.1028</td>
                <td>411</td>
            </tr>
            <tr>
                <td>bunny_microfacet_cu.dae</td>
                <td>0.1042</td>
                <td>451</td>
            </tr>
            <tr>
                <td>bunny_unlit.dae</td>
                <td>0.1054</td>
                <td>468</td>
            </tr>
            <tr>
                <td>bunny.dae</td>
                <td>0.1043</td>
                <td>435</td>
            </tr>
        </table>
    </section>

<h1>3. Direct Illumination</h1>
<h2>Direct Lighting Function Implementations</h2>

    <h3>1. Uniform Hemisphere Sampling</h3>
    <p>This method samples directions uniformly across the hemisphere oriented by the surface normal at the hit point. It calculates the direct lighting contribution by casting shadow rays towards the sampled directions and checking for occlusions.</p>
    <p>The main steps are:</p>
    <ul>
        <li>Create a local coordinate system at the intersection point, with the surface normal as the up direction.</li>
        <li>Uniformly sample directions across the hemisphere.</li>
        <li>For each sampled direction, create a shadow ray from the hit point in the sampled direction.</li>
        <li>Check for intersections with the scene. If the shadow ray reaches the light without occlusion, calculate the contribution of this light to the direct illumination at the hit point.</li>
        <li>Average the contributions from all samples to estimate the direct lighting at the point.</li>
    </ul>

    <h3>2. Importance Sampling of Lights</h3>
    <p>This approach directly samples the light sources based on their contribution to the point of interest, which reduces variance and improves the quality of the rendering with fewer samples compared to uniform sampling.</p>
    <p>The main steps are:</p>
    <ul>
        <li>For each light source in the scene, calculate the direction from the hit point to the light and the distance to the light.</li>
        <li>Create a shadow ray from the hit point towards each light source.</li>
        <li>If the shadow ray reaches the light source without occlusion, calculate the light's contribution to the direct illumination at the hit point based on the surface's BRDF, the angle between the light direction and the surface normal, and the distance to the light.</li>
        <li>Accumulate the contributions from all visible light sources to estimate the direct lighting at the point.</li>
    </ul>

    <p>Both methods aim to accurately estimate the direct lighting component of global illumination by considering the light that arrives directly from light sources to the surfaces in the scene. The choice between uniform hemisphere sampling and importance sampling depends on the scene's complexity, the distribution and intensity of light sources, and the desired trade-off between render time and noise.</p>

<h3>Comparison of Different Sampling</h3>

    <div style="text-align: center;">
    <figure>
        <img src="assets/3_0.png" style="width:20vw;">
	<img src="assets/3_1.png" style="width:20vw;">
	<img src="assets/3_2.png" style="width:20vw;">
	    <img src="assets/3_3.png" style="width:20vw;">
	    <img src="assets/3_4.png" style="width:20vw;">
	    <img src="assets/3_5.png" style="width:20vw;">
	    <img src="assets/3_6.png" style="width:20vw;">
	    <img src="assets/3_7.png" style="width:20vw;">
        <figcaption> Top is hemisphere and bottom is importance sampling.</figcaption>
    </figure>
    </div>
<p>Based on the comparison of images provided, the renders utilizing light sampling demonstrate a noticeable reduction in noise, particularly within the softer shadows, when compared to those using uniform hemisphere sampling. This reduction is most evident in the transition areas between illuminated and shadowed regions. Light sampling results in images with clearer definition and contrast between these areas due to the sampling method's alignment with the distribution and intensity of the light sources. Conversely, hemisphere sampling's uniform distribution over the hemisphere does not consider light source directionality or intensity, leading to increased noise and less accurate depiction of shadow softness. The images showcase light sampling's advantages in scenes where soft shadows and nuanced lighting effects are significant to the overall visual impact. By focusing computational resources on areas with the most significant visual contribution, light sampling yields cleaner, more precise renders with fewer samples. This is particularly crucial in complex scenes with multiple light sources or materials with different reflective properties, where accurate shadows and light interplay are essential for realism. While light sampling offers clear benefits in noise reduction and shadow fidelity, it may also require additional computational effort to identify relevant light sources for each scene point, underscoring the critical trade-off between computational complexity and render quality in path tracing and global illumination.</p>

<h3>Soft Shadow Noise Comparison</h3>
<p>Comparing the noise levels in soft shadows with different numbers of light rays during rendering.</p>

<div style="text-align: center;">
  <img src="assets/33_0.png" alt="1 Light Ray" style="width:100%;max-width:300px">
  <img src="assets/33_1.png" alt="4 Light Rays" style="width:100%;max-width:300px">
  <img src="assets/33_2.png" alt="16 Light Rays" style="width:100%;max-width:300px">
  <img src="assets/33_3.png" alt="64 Light Rays" style="width:100%;max-width:300px">
  <figcaption> 1 / 4 / 16 / 64 Light Ray</figcaption>
</div>


<h1>4. Global Illumination</h1>
<h2>Indirect Lighting Function Implementation</h2>
<p>The indirect lighting in our path tracer is computed by recursively sampling the scene's hemispherical light distribution. Starting with the direct lighting component, which is computed using either hemisphere or importance sampling, the algorithm then progresses to calculate indirect illumination. It does this by generating a new sample ray from the intersection point in a direction sampled from the BSDF. This new ray is recursively passed to the at_least_one_bounce_radiance function, which calculates the radiance contribution of the subsequent path segment. If the ray depth reaches the predefined maximum or the Russian Roulette termination condition is met, the recursion stops and the accumulated radiance is returned. Each sample's contribution is weighted by the cosine of the angle it makes with the normal at the intersection point and divided by the probability density function (PDF) associated with the BSDF's sampling strategy. This ensures that the illumination is unbiased and accurately represents the complex interplay of light in the scene. For non-delta materials, emission is returned directly, while for delta materials, which include perfect mirrors and glass, a special reflection or refraction shader is invoked to handle their unique interaction with light.</p>

<h2>Some Rendered Images</h2>

<div style="text-align: center;">
  <img src="assets/5_0.png" alt="1 Light Ray" style="width:100%;max-width:300px">
  <img src="assets/4_1.png" alt="4 Light Rays" style="width:100%;max-width:300px">
  <img src="assets/4_2.png" alt="16 Light Rays" style="width:100%;max-width:300px">
  <img src="assets/4_3.png" alt="64 Light Rays" style="width:100%;max-width:300px">
  <figcaption> 1 / 4 / 16 / 64 Light Ray</figcaption>
</div>


<h2>Only Direct vs. Only Indirect</h2>
<div style="text-align: center;">
  <img src="assets/4_4.png" style="width:100%;max-width:300px">
  <img src="assets/44444_2.png" style="width:100%;max-width:300px">
  <figcaption> Left: only direct; right: only indirect. light source here is not excluded</figcaption>
</div>


<h2>Different Number of Bounces and isAccumBounces=false</h2>
<p>
In the rendered images, the 2nd and 3rd bounces of light capture the subtle interplay of light as it reflects off multiple surfaces, adding depth and realism to the scene that rasterization typically lacks. These additional bounces allow for the simulation of complex lighting phenomena such as color bleeding, where light reflects off a colored surface and indirectly tints neighboring areas with its hue. This contributes significantly to the overall image quality, as it introduces a more of a natural light behavior.</p>
<div style="text-align: center;">
  <img src="assets/44_0.png" style="width:100%;max-width:300px">
  <img src="assets/44_1.png" style="width:100%;max-width:300px">
  <img src="assets/44444_2.png" style="width:100%;max-width:300px">
  <img src="assets/44444_3.png" style="width:100%;max-width:300px">
  <img src="assets/44444_4.png" style="width:100%;max-width:300px">
  <img src="assets/44444_5.png" style="width:100%;max-width:300px">
  <figcaption> Different number of bounces from 0 to 5</figcaption>
</div>

<h2>Different Number of Bounces</h2>
<p>We can see that after the 2nd iter the images are almost the same.</p>
<div style="text-align: center;">
  <img src="assets/44_0.png" style="width:100%;max-width:300px">
  <img src="assets/44_1.png" style="width:100%;max-width:300px">
  <img src="assets/44_2.png" style="width:100%;max-width:300px">
  <img src="assets/44_3.png" style="width:100%;max-width:300px">
  <img src="assets/44_4.png" style="width:100%;max-width:300px">
  <img src="assets/44_5.png" style="width:100%;max-width:300px">
  <figcaption> Different number of bounces from 0 to 5</figcaption>
</div>

<h2>Different Number of Bounces with Russian Roulette rendering </h2>
<p>max_ray_depth = 100: Although this depth aims for an extremely high level of accuracy in simulating light transport, it's likely that visual differences between depth 100 and much lower depths like 4 or 5 will be minimal to the human eye.</p>
<div style="text-align: center;">
  <img src="assets/44_0.png" style="width:100%;max-width:300px">
  <img src="assets/44_1.png" style="width:100%;max-width:300px">
  <img src="assets/44_2.png" style="width:100%;max-width:300px">
  <img src="assets/44_3.png" style="width:100%;max-width:300px">
  <img src="assets/44_4.png" style="width:100%;max-width:300px">
  <img src="assets/444_5.png" style="width:100%;max-width:300px">
  <figcaption> Different number of bounces from 0 to 4 and 100</figcaption>
</div>

<h2>Different Sample Rates </h2>
<p>We can see that by using higher sample rates, the smoother the scene becomes.</p>
<div style="text-align: center;">
  <img src="assets/4444_0.png" style="width:100%;max-width:300px">
  <img src="assets/4444_1.png" style="width:100%;max-width:300px">
  <img src="assets/4444_2.png" style="width:100%;max-width:300px">
  <img src="assets/4444_3.png" style="width:100%;max-width:300px">
  <img src="assets/4444_4.png" style="width:100%;max-width:300px">
  <img src="assets/4444_5.png" style="width:100%;max-width:300px">
  <img src="assets/4444_6.png" style="width:100%;max-width:300px">
  <figcaption> Different sample rates 1, 2, 4, 8, 16, 64, 1024</figcaption>
</div>

<h1>5. Adaptive Sampling</h1>
<h2>Adaptive Sampling Explanation</h2>
<p>Adaptive sampling is an optimization technique that adjusts the number of samples taken per pixel based on the variance of the lighting within that pixel's region. The goal is to allocate more samples to areas with higher variance—typically edges or areas with complex lighting—to reduce noise, while using fewer samples in more uniform areas. In the implementation, we start by sampling each pixel a few times and computing the variance of the radiance. If the variance is above a certain threshold, we continue to sample, up to a maximum sample limit. This ensures that the computational effort is focused on areas where it is most needed, enabling faster rendering times without sacrificing image quality.</p>

 <h2>Sampling</h2>
 <div style="text-align: center;">
  <img src="assets/5_0.png" style="width:100%;max-width:300px" alt="Uniform Hemisphere Sampling Image 1">
  <img src="assets/5_0_rate.png" style="width:100%;max-width:300px" alt="Uniform Hemisphere Sampling Image 2">
  <img src="assets/5_1.png" style="width:100%;max-width:300px" alt="Uniform Hemisphere Sampling Image 1">
  <img src="assets/5_1_rate.png" style="width:100%;max-width:300px" alt="Uniform Hemisphere Sampling Image 2">
  <figcaption>both of sample rate image</figcaption>
</div>


</body>
</html>
